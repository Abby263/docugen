# DeepSearch CodeBuddy Environment Configuration Example File
# Copy this file to .env and fill in the actual configuration values

# ===========================================
# Langfuse Monitoring Configuration (Required)
# ===========================================
# How to obtain: Visit https://cloud.langfuse.com to register and create a project
LANGFUSE_SECRET_KEY=sk-lf-xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx
LANGFUSE_PUBLIC_KEY=pk-lf-xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx
LANGFUSE_HOST=https://cloud.langfuse.com

# ===========================================
# LLM API Configuration (Configure at least one)
# ===========================================

# Qwen (Recommended, default)
# How to obtain: Visit https://dashscope.console.aliyun.com/ to get API Key
DASHSCOPE_API_KEY=your_dashscope_api_key_here

# OpenAI
# How to obtain: Visit https://platform.openai.com/api-keys to get API Key
OPENAI_API_KEY=your_openai_api_key_here

# Anthropic Claude
# How to obtain: Visit https://console.anthropic.com/ to get API Key
ANTHROPIC_API_KEY=your_anthropic_api_key_here

# Zhipu AI
# How to obtain: Visit https://open.bigmodel.cn/ to get API Key
ZHIPU_API_KEY=your_zhipu_api_key_here

# DeepSeek
# How to obtain: Visit https://platform.deepseek.com/ to get API Key
DEEPSEEK_API_KEY=your_deepseek_api_key_here

# Azure OpenAI (Enterprise users)
AZURE_OPENAI_API_KEY=your_azure_openai_api_key_here
AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com/

# ===========================================
# Search Service Configuration (Optional)
# ===========================================
# Perplexity API (Recommended for advanced search)
# How to obtain: Visit https://www.perplexity.ai/settings/api to get API Key
PERPLEXITY_API_KEY=your_perplexity_api_key_here

# Zhipu Web Search MCP Service
# How to obtain: Visit https://open.bigmodel.cn/ to get API Key
# If configured, the system will prioritize using Zhipu Web Search service to avoid DuckDuckGo limitations
# Format: API Key or AK.SK format
ZHIPU_MCP_API_KEY=your_zhipu_mcp_api_key_here

# Future extensible MCP services
# OTHER_MCP_API_KEY=your_other_mcp_api_key_here

# ===========================================
# Image Search API Configuration (Optional - for document illustrations)
# ===========================================
# Unsplash API (Recommended - high quality free images)
# How to obtain:
# 1. Visit https://unsplash.com/developers
# 2. Register and create an application
# 3. Get Access Key
# Free quota: 5000 requests/hour
UNSPLASH_ACCESS_KEY=your_unsplash_access_key_here

# Pexels API (Alternative - completely free)
# How to obtain:
# 1. Visit https://www.pexels.com/api/
# 2. Register and create an application
# 3. Get API Key
# Unlimited free usage
PEXELS_API_KEY=your_pexels_api_key_here

# Image feature configuration
# Enable document illustrations (true/false)
ENABLE_DOCUMENT_IMAGES=true
# Number of images per section
IMAGES_PER_SECTION=2
# Image insertion mode: smart, top, bottom, distribute, none
IMAGE_INSERT_MODE=smart

# ===========================================
# Default LLM Configuration
# ===========================================
# Supported providers: qwen, openai, anthropic, zhipu, deepseek, azure_openai, ollama
DEFAULT_LLM_PROVIDER=qwen

# Model name (choose corresponding model based on provider)
# Qwen: qwen-turbo, qwen-plus, qwen-max
# OpenAI: gpt-4o-mini, gpt-4o, gpt-3.5-turbo
# Anthropic: claude-3-haiku-20250307, claude-3-sonnet-20250229
# Zhipu AI: glm-4, glm-4-flash
# DeepSeek: deepseek-chat, deepseek-coder
DEFAULT_LLM_MODEL=qwen-turbo

# Generation parameters
DEFAULT_LLM_TEMPERATURE=0.7
DEFAULT_LLM_MAX_TOKENS=4000

# ===========================================
# Project Configuration
# ===========================================
PROJECT_NAME=DeepSearch CodeBuddy
PROJECT_VERSION=1.0.0
DEBUG=false

# ===========================================
# Usage Instructions
# ===========================================
# 1. Copy this file to .env
# 2. Configure at least one LLM API key (Qwen recommended)
# 3. Configure Langfuse monitoring (for LLM call monitoring and analysis)
# 4. Adjust default LLM configuration as needed
# 5. Run python main_simple_test.py to test the system
